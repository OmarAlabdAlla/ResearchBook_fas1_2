#!/usr/bin/env python3

import requests
import json

def test_specific_models():
    """Test specific models that look more promising"""
    
    url = "https://anast.ita.chalmers.se:4000/v1/chat/completions"
    api_key = "sk-u_7AVwCgIBRZF9IXwzPqtA"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Try models that look more likely to work
    promising_models = [
        "claude-sonnet-4",
        "claude-sonnet-3.7", 
        "claude-haiku-3.5",
        "ollama/llama3.3",
        "o3-mini-2025-01-31"
    ]
    
    for model in promising_models:
        print(f"\nüß™ Testing model: {model}")
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user", 
                    "content": "Hello! Please respond with exactly this text: 'LightLLM API test successful with model " + model + "'"
                }
            ],
            "max_tokens": 100,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30, verify=False)
            
            print(f"   Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("   ‚úÖ SUCCESS!")
                
                if 'choices' in result and len(result['choices']) > 0:
                    message_content = result['choices'][0]['message']['content']
                    print(f"   ü§ñ Response: {message_content}")
                    
                    if 'usage' in result:
                        usage = result['usage']
                        print(f"   üìä Tokens used: {usage}")
                    
                    # Test with a more complex query
                    print(f"\nüî¨ Testing complex query with {model}...")
                    complex_payload = {
                        "model": model,
                        "messages": [
                            {
                                "role": "user", 
                                "content": "Analyze this research scenario: A postdoc at Chalmers worked on AI from 2020-2022, then moved to MIT. What type of academic career transition does this represent? Respond in exactly 2 sentences."
                            }
                        ],
                        "max_tokens": 150,
                        "temperature": 0.3
                    }
                    
                    complex_response = requests.post(url, headers=headers, json=complex_payload, timeout=30, verify=False)
                    
                    if complex_response.status_code == 200:
                        complex_result = complex_response.json()
                        complex_content = complex_result['choices'][0]['message']['content']
                        print(f"   üß† Complex response: {complex_content}")
                        
                        return model, True
                    else:
                        print(f"   ‚ö†Ô∏è Complex query failed: {complex_response.status_code}")
                        return model, True  # Simple test worked at least
                        
                else:
                    print("   ‚ö†Ô∏è Unexpected response format")
                    print(f"   Response: {json.dumps(result, indent=2)}")
                    
            else:
                print(f"   ‚ùå Failed: {response.status_code}")
                try:
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', 'Unknown error')
                    print(f"   Error: {error_msg}")
                except:
                    print(f"   Raw error: {response.text[:200]}")
                    
        except Exception as e:
            print(f"   ‚ùå Exception: {e}")
    
    return None, False

if __name__ == "__main__":
    working_model, success = test_specific_models()
    
    print(f"\nüìã LightLLM API Test Summary:")
    print(f"   Endpoint: https://anast.ita.chalmers.se:4000/v1/chat/completions")
    print(f"   API Key: ‚úÖ Valid format")
    print(f"   Models available: ‚úÖ 21 models found")
    print(f"   Working model: {'‚úÖ ' + working_model if working_model else '‚ùå None found'}")
    print(f"   Chat completions: {'‚úÖ Functional' if success else '‚ùå Not working'}")
    
    if working_model:
        print(f"\nüéâ SUCCESS! You can use model: {working_model}")
        print("   This API can be used for:")
        print("   ‚Ä¢ Research analysis and summarization")
        print("   ‚Ä¢ Academic relationship interpretation") 
        print("   ‚Ä¢ Generating research intelligence reports")
        print("   ‚Ä¢ Processing graph data insights")